{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3eb9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/vishal/Volume_E/Active/Gap_year/grand-project-2025/deepak/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env_name': 'TwoArmBoxCleanup', 'env_version': '1.5.1', 'type': 1, 'env_kwargs': {'robots': ['PandaDexRH', 'PandaDexLH'], 'controller_configs': {'type': 'BASIC', 'body_parts': {'right': {'type': 'OSC_POSE', 'input_max': 1, 'input_min': -1, 'output_max': [0.05, 0.05, 0.05, 0.5, 0.5, 0.5], 'output_min': [-0.05, -0.05, -0.05, -0.5, -0.5, -0.5], 'kp': 150, 'damping_ratio': 1, 'impedance_mode': 'fixed', 'kp_limits': [0, 300], 'damping_ratio_limits': [0, 10], 'position_limits': None, 'orientation_limits': None, 'uncouple_pos_ori': True, 'input_type': 'delta', 'input_ref_frame': 'base', 'interpolation': None, 'ramp_ratio': 0.2, 'gripper': {'type': 'GRIP', 'use_action_scaling': False}}}}, 'translucent_robot': False, 'env_configuration': 'parallel', 'reward_shaping': False, 'camera_names': ['agentview', 'robot0_eye_in_hand', 'robot1_eye_in_hand'], 'camera_heights': 84, 'camera_widths': 84, 'has_renderer': False, 'has_offscreen_renderer': True, 'ignore_done': True, 'use_object_obs': True, 'use_camera_obs': True, 'camera_depths': False, 'render_gpu_device_id': 0, 'env_lang': None}}\n"
     ]
    }
   ],
   "source": [
    "import robosuite \n",
    "import dexmimicgen  \n",
    "\n",
    "import h5py \n",
    "import imageio \n",
    "import numpy as np\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "\n",
    "'''\n",
    "\n",
    "1. Loading dual robot environment\n",
    "'''\n",
    "\n",
    "# def get_env_metadata_from_dataset(dataset_path, ds_format=\"robomimic\"):\n",
    "#     \"\"\"\n",
    "#     Retrieves env metadata from dataset.\n",
    "\n",
    "#     Args:\n",
    "#         dataset_path (str): path to dataset\n",
    "\n",
    "#     Returns:\n",
    "#         env_meta (dict): environment metadata. Contains 3 keys:\n",
    "\n",
    "#             :`'env_name'`: name of environment\n",
    "#             :`'type'`: type of environment, should be a value in EB.EnvType\n",
    "#             :`'env_kwargs'`: dictionary of keyword arguments to pass to environment constructor\n",
    "#     \"\"\"\n",
    "#     dataset_path = os.path.expanduser(dataset_path)\n",
    "#     f = h5py.File(dataset_path, \"r\")\n",
    "#     if ds_format == \"robomimic\":\n",
    "#         env_meta = json.loads(f[\"data\"].attrs[\"env_args\"])\n",
    "#     else:\n",
    "#         raise ValueError\n",
    "#     f.close()\n",
    "#     return env_meta\n",
    "\n",
    "from vishal_dev.utils import get_env_metadata_from_dataset\n",
    "\n",
    "dataset_path = \"/home/vishal/Volume_E/Active/Gap_year/grand-project-2025/deepak/dexmimicgen/datasets/two_arm_box_cleanup.hdf5\"\n",
    "\n",
    "env_meta = get_env_metadata_from_dataset(dataset_path)\n",
    "print(env_meta)\n",
    "\n",
    "write_to_video = False\n",
    "\n",
    "env_kwargs = env_meta['env_kwargs']\n",
    "env_kwargs[\"env_name\"] = env_meta[\"env_name\"]\n",
    "env_kwargs[\"has_renderer\"] = True\n",
    "env_kwargs[\"renderer\"] = \"mjviewer\"\n",
    "env_kwargs[\"has_offscreen_renderer\"] = write_to_video # False # write_video\n",
    "env_kwargs[\"use_camera_obs\"] = False\n",
    "\n",
    "env_kwargs.pop(\"env_lang\")\n",
    "\n",
    "env = robosuite.make(**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf35208",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pose_utils_vishal_from_mimicgen as PoseUtils\n",
    "import robosuite.utils.transform_utils as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extracting a demonstration from the dataset\n",
    "'''\n",
    "\n",
    "data = h5py.File(dataset_path, \"r\")\n",
    "print(f\"Keys in the dataset: {data['data'].keys()}\")\n",
    "print(f\"Number of demonstrations in the dataset: {len(data['data'].keys())}\")\n",
    "demo_id = 'demo_15'\n",
    "print(f\"Length of demo {demo_id}: {data['data'][demo_id]['obs']['robot0_eef_pos'].shape[0]}\")\n",
    "print(f\"Observations shape: {data['data'][demo_id]['obs'].keys()}\")\n",
    "print(f\"Actions shape: {data['data'][demo_id]['actions'].shape}\")\n",
    "print(f\"Actions: {data['data'][demo_id]['actions']}\")\n",
    "print(f\"Actions shape: {data['data'][demo_id]['actions'].shape}\")\n",
    "print(f\"Action at step 0: {data['data'][demo_id]['actions'][0]}\")\n",
    "\n",
    "action_trajectory = data['data'][demo_id]['actions']\n",
    "obs_trajectory = data['data'][demo_id]['obs']\n",
    "states_trajectory = data['data'][demo_id]['states']\n",
    "\n",
    "eef_poses = data['data'][demo_id]['datagen_info']['eef_pose']\n",
    "gripper_actions = data['data'][demo_id]['datagen_info']['gripper_action']\n",
    "target_eef_poses = data['data'][demo_id]['datagen_info']['target_pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vishal_dev.utils import just_reset, reset_to_state, reset_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1919386",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = demo_id\n",
    "states = data[\"data/{}/states\".format(ep)][()]\n",
    "initial_state = dict(states=states[0])\n",
    "initial_state[\"model\"] = data[\"data/{}\".format(ep)].attrs[\"model_file\"]\n",
    "# if args.use_current_model:\n",
    "initial_state[\"model\"] = env.sim.model.get_xml()\n",
    "initial_state[\"ep_meta\"] = data[\"data/{}\".format(ep)].attrs.get(\"ep_meta\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd238fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Replay a demonstration\n",
    "'''\n",
    "# reset_to_state(env, states_trajectory[0])\n",
    "# just_reset(env, states_trajectory[25])\n",
    "\n",
    "for i in range(action_trajectory.shape[0]):\n",
    "    action = action_trajectory[i]\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf680171",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dpos = 0.05\n",
    "max_drot = 0.5\n",
    "\n",
    "from vishal_dev.utils import eef_to_action_single_arm, eef_to_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bf526",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data class for source and transformed segments\n",
    "\n",
    "inputs:\n",
    "    arm1_src_traj: (N, 4, 4) numpy array\n",
    "    arm2_src_traj: (N, 4, 4) numpy array\n",
    "    starting_lid_pose: (4, 4) numpy array\n",
    "    starting_box_pose: (4, 4) numpy array\n",
    "\n",
    "to_maintain:\n",
    "    arm1_src_segment1: (N, 4, 4) numpy array\n",
    "    arm1_src_segment2: (N, 4, 4) numpy array\n",
    "    arm2_src_segment1: (N, 4, 4) numpy array\n",
    "    arm2_src_segment2: (N, 4, 4) numpy array\n",
    "    starting_lid_pose: (4, 4) numpy array\n",
    "    starting_box_pose: (4, 4) numpy array\n",
    "    arm1_tgt_segment1: (N, 4, 4) numpy array\n",
    "    arm1_tgt_segment2: (N, 4, 4) numpy array\n",
    "    arm2_tgt_segment1: (N, 4, 4) numpy array\n",
    "    arm2_tgt_segment2: (N, 4, 4) numpy array\n",
    "    \n",
    "    INTERPOLATED TRAJECTORIES\n",
    "    arm1_interp_toseg1: (N, 4, 4) numpy array\n",
    "    arm1_interp_toseg2: (N, 4, 4) numpy array\n",
    "    arm2_interp_toseg1: (N, 4, 4) numpy array\n",
    "    arm2_interp_toseg2: (N, 4, 4) numpy array\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bca547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obfull[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now prepare the data\n",
    "'''\n",
    "obfull = just_reset(env, states_trajectory[0])\n",
    "src_lid_pos = data['data'][demo_id]['datagen_info']['object_poses']['lid'][0][:3, 3]\n",
    "src_lid_mat = data['data'][demo_id]['datagen_info']['object_poses']['lid'][0][:3, :3].reshape(3, 3)\n",
    "src_box_pos = data['data'][demo_id]['datagen_info']['object_poses']['box'][0][:3, 3]\n",
    "src_box_mat = data['data'][demo_id]['datagen_info']['object_poses']['box'][0][:3, :3].reshape(3, 3)\n",
    "src_lid_pose = PoseUtils.make_pose(src_lid_pos, src_lid_mat)\n",
    "src_box_pose = PoseUtils.make_pose(src_box_pos, src_box_mat)\n",
    "print(\"Starting lid pose: \", src_lid_pose)\n",
    "print(\"Starting box pose: \", src_box_pose)\n",
    "\n",
    "new_lid_pos = env.sim.data.body('lid_obj_root').xpos\n",
    "new_lid_mat = env.sim.data.body('lid_obj_root').xmat.reshape(3, 3)\n",
    "new_box_pos = env.sim.data.body('box_obj_root').xpos\n",
    "new_box_mat = env.sim.data.body('box_obj_root').xmat.reshape(3, 3)\n",
    "new_lid_pose = PoseUtils.make_pose(new_lid_pos, new_lid_mat)\n",
    "new_box_pose = PoseUtils.make_pose(new_box_pos, new_box_mat)\n",
    "print(\"New lid pose: \", new_lid_pose)\n",
    "print(\"New box pose: \", new_box_pose)\n",
    "\n",
    "cur_arm1_eef_pos = obfull[0]['robot0_eef_pos']\n",
    "cur_arm1_eef_mat = obfull[0]['robot0_eef_quat']\n",
    "cur_arm1_eef_mat = T.quat2mat(cur_arm1_eef_mat)\n",
    "cur_arm1_eef_pose = PoseUtils.make_pose(cur_arm1_eef_pos, cur_arm1_eef_mat)\n",
    "print(\"Current arm1 eef pose: \", cur_arm1_eef_pose)\n",
    "cur_arm2_eef_pos = obfull[0]['robot1_eef_pos']\n",
    "cur_arm2_eef_mat = obfull[0]['robot1_eef_quat']\n",
    "cur_arm2_eef_mat = T.quat2mat(cur_arm2_eef_mat)\n",
    "cur_arm2_eef_pose = PoseUtils.make_pose(cur_arm2_eef_pos, cur_arm2_eef_mat)\n",
    "print(\"Current arm2 eef pose: \", cur_arm2_eef_pose)\n",
    "cur_eef_poses = np.zeros((2, 4, 4))\n",
    "cur_eef_poses[0, :, :] = cur_arm1_eef_pose\n",
    "cur_eef_poses[1, :, :] = cur_arm2_eef_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424516ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transforming the source trajectories to the new object positions\n",
    "'''\n",
    "\n",
    "'''\n",
    "Transforming two segments one by one\n",
    "\n",
    "Process:\n",
    "1. Transform segment 1 using object pose at start of segment 1\n",
    "2. Interpolate between starting pose to starting pose of segment 1\n",
    "3. Transform segment 2 using object pose at start of segment 2\n",
    "4. Interpolate between end of segment 1 to starting pose of segment 2\n",
    "\n",
    "'''\n",
    "\n",
    "from pose_utils_vishal_from_mimicgen import transform_source_data_segment_using_object_pose\n",
    "from pose_utils_vishal_from_mimicgen import interpolate_poses\n",
    "from pose_utils_vishal_from_mimicgen import make_pose\n",
    "from pose_utils_vishal_from_mimicgen import unmake_pose\n",
    "\n",
    "def transform_two_segments_for_one_arm(\n",
    "        segment1,\n",
    "        segment2,\n",
    "        src_obj1_pose,\n",
    "        cur_obj1_pose,\n",
    "        src_obj2_pose,\n",
    "        cur_obj2_pose,\n",
    "        starting_eef_pose,\n",
    "    ):\n",
    "    '''Transform 2 segments of trajectory from source to current based on object poses\n",
    "\n",
    "    Args:\n",
    "        segment1 (list): list of eef_poses for segment 1 (T, 4, 4)\n",
    "        segment2 (list): list of eef_poses for segment 2 (T, 4, 4)\n",
    "        src_obj1_pose (np.ndarray): source object pose (4, 4)\n",
    "        cur_obj1_pose (np.ndarray): current object pose (4, 4)\n",
    "        src_obj2_pose (np.ndarray): source object pose (4, 4)\n",
    "        cur_obj2_pose (np.ndarray): current object pose (4, 4)\n",
    "        starting_eef_pose (list): starting eef pose (4, 4)\n",
    "    Returns:\n",
    "        \n",
    "    '''\n",
    "    # Transform segments into their corresponding target object poses\n",
    "    transformed_segment1 = transform_source_data_segment_using_object_pose(\n",
    "        src_eef_poses=segment1,\n",
    "        src_obj_pose=src_obj1_pose,\n",
    "        obj_pose=cur_obj1_pose,\n",
    "    )\n",
    "    transformed_segment2 = transform_source_data_segment_using_object_pose(\n",
    "        src_eef_poses=segment2,\n",
    "        src_obj_pose=src_obj2_pose,\n",
    "        obj_pose=cur_obj2_pose,\n",
    "    )\n",
    "\n",
    "    # Interpolate between starting pose to starting pose of segment 1\n",
    "    interp_poses0, num_steps = interpolated_poses = interpolate_poses(\n",
    "        pose_1=starting_eef_pose,\n",
    "        pose_2=transformed_segment1[0],\n",
    "        num_steps=10,\n",
    "        # step_size=0.1, # one of step size or num_steps is needed\n",
    "    )\n",
    "\n",
    "    # Interpolate between end of segment 1 to starting pose of segment 2\n",
    "    interp_poses1, num_steps = interpolated_poses = interpolate_poses(\n",
    "        pose_1=transformed_segment1[-1],\n",
    "        pose_2=transformed_segment2[0],\n",
    "        num_steps=10,\n",
    "        # step_size=0.1, # one of step size or num_steps is needed\n",
    "    )\n",
    "\n",
    "    # Create a dict of all trajectories \n",
    "    overall_trajectory = {\n",
    "        'interp_to_segment1': interp_poses0,\n",
    "        'segment1': transformed_segment1,\n",
    "        'interp_to_segment2': interp_poses1,\n",
    "        'segment2': transformed_segment2,\n",
    "    }\n",
    "\n",
    "    return overall_trajectory\n",
    "\n",
    "def get_transformed_segments_for_both_arms(\n",
    "        segment1,\n",
    "        segment2,\n",
    "        src_obj1_pose,\n",
    "        cur_obj1_pose,\n",
    "        src_obj2_pose,\n",
    "        cur_obj2_pose,\n",
    "        starting_eef_pose,\n",
    "    ):\n",
    "    '''\n",
    "\n",
    "    args:\n",
    "        segment1 (np.ndarray): (N, 2, 4, 4)\n",
    "        segment2 (np.ndarray): (M, 2, 4, 4) \n",
    "        src_obj1_pose (np.ndarray): (4, 4)\n",
    "        cur_obj1_pose (np.ndarray): (4, 4)\n",
    "        src_obj2_pose (np.ndarray): (4, 4)\n",
    "        cur_obj2_pose (np.ndarray): (4, 4)\n",
    "        starting_eef_pose (list): list of two eef poses [(4, 4), (4, 4)]\n",
    "    returns:\n",
    "        dict: {\n",
    "            \"arm1\": {\n",
    "                \"overall_trajectory\": overall_trajectory_arm1 (dict): {\n",
    "                    'interp_to_segment1': interp_poses0,\n",
    "                    'segment1': transformed_segment1,\n",
    "                    'interp_to_segment2': interp_poses1,\n",
    "                    'segment2': transformed_segment2,\n",
    "                },\n",
    "                \"starting_eef_pose\": starting_eef_pose_arm1 (list): [(4, 4)]\n",
    "            },\n",
    "            \"arm2\": {\n",
    "                \"overall_trajectory\": overall_trajectory_arm2 (dict): {\n",
    "                    'interp_to_segment1': interp_poses0,\n",
    "                    'segment1': transformed_segment1,\n",
    "                    'interp_to_segment2': interp_poses1,\n",
    "                    'segment2': transformed_segment2,\n",
    "                },\n",
    "                \"starting_eef_pose\": starting_eef_pose_arm2 (list): [(4, 4)]\n",
    "            }\n",
    "        }\n",
    "    '''\n",
    "\n",
    "    arm1_segment1 = segment1[:, 0, :, :]\n",
    "    arm1_segment2 = segment2[:, 0, :, :]\n",
    "    arm2_segment1 = segment1[:, 1, :, :]\n",
    "    arm2_segment2 = segment2[:, 1, :, :]\n",
    "    starting_eef_pose_arm1 = starting_eef_pose[0] # [starting_eef_pose[0][0], starting_eef_pose[1][0]]\n",
    "    starting_eef_pose_arm2 = starting_eef_pose[1] # [starting_eef_pose[0][1], starting_eef_pose[1][1]]\n",
    "\n",
    "    overall_trajectory_arm1 = transform_two_segments_for_one_arm(\n",
    "        segment1=arm1_segment1,\n",
    "        segment2=arm1_segment2,\n",
    "        src_obj1_pose=src_obj1_pose,\n",
    "        cur_obj1_pose=cur_obj1_pose,\n",
    "        src_obj2_pose=src_obj2_pose,\n",
    "        cur_obj2_pose=cur_obj2_pose,\n",
    "        starting_eef_pose=starting_eef_pose_arm1,\n",
    "    )\n",
    "\n",
    "    overall_trajectory_arm2 = transform_two_segments_for_one_arm(\n",
    "        segment1=arm2_segment1,\n",
    "        segment2=arm2_segment2,\n",
    "        src_obj1_pose=src_obj1_pose,\n",
    "        cur_obj1_pose=cur_obj1_pose,\n",
    "        src_obj2_pose=src_obj2_pose,\n",
    "        cur_obj2_pose=cur_obj2_pose,\n",
    "        starting_eef_pose=starting_eef_pose_arm2,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"arm1\": {\n",
    "            \"overall_trajectory\": overall_trajectory_arm1,\n",
    "            \"starting_eef_pose\": starting_eef_pose_arm1\n",
    "        },\n",
    "        \"arm2\": {\n",
    "            \"overall_trajectory\": overall_trajectory_arm2,\n",
    "            \"starting_eef_pose\": starting_eef_pose_arm2\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_eef_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f88a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vishal_dev.utils import segment_trajectory\n",
    "\n",
    "segments = segment_trajectory(data, demo_id)\n",
    "\n",
    "src_arm_segment1 = target_eef_poses[:segments[0][-1]+1, :]\n",
    "src_arm_segment2 = target_eef_poses[:segments[1][-1]+1, :]\n",
    "\n",
    "full_trajectory_outs = get_transformed_segments_for_both_arms(\n",
    "    segment1=src_arm_segment1,\n",
    "    segment2=src_arm_segment2,\n",
    "    src_obj1_pose=src_lid_pose,\n",
    "    cur_obj1_pose=new_lid_pose,\n",
    "    src_obj2_pose=src_box_pose,\n",
    "    cur_obj2_pose=new_box_pose,\n",
    "    starting_eef_pose=cur_eef_poses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_data = get_transformed_segments_for_both_arms(\n",
    "#     segment1=eef_poses[0],\n",
    "#     segment2=eef_poses[1],\n",
    "#     src_obj1_pose=src_lid_pose,\n",
    "#     cur_obj1_pose=new_lid_pose,\n",
    "#     src_obj2_pose=src_box_pose,\n",
    "#     cur_obj2_pose=new_box_pose,\n",
    "#     starting_eef_pose=target_eef_poses,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Execution order/logic for trajectories:\n",
    "\n",
    "# 1. Interpolate to initial poses for each arm in parallel\n",
    "N, M = len(arm1_interp_toseg1), len(arm2_interp_toseg1)\n",
    "\n",
    "for i in range(max(N, M)):\n",
    "    initialize action with zeros\n",
    "    if i < N:\n",
    "        set action[0:12] to arm1_interp_toseg1[i]\n",
    "    if i < M:\n",
    "        set action[12:24] to arm2_interp_toseg1[i]\n",
    "    env.step(action)\n",
    "\n",
    "# 2. Execute segment1 for each arm in parallel. This segment will be of same length for both arms\n",
    "\n",
    "for i in range(len(arm1_segment1)):\n",
    "    initialize action with zeros\n",
    "    set action[0:12] to arm1_segment1[i]\n",
    "    set action[12:24] to arm2_segment1[i]\n",
    "    env.step(action)\n",
    "\n",
    "# 3. Interpolate to initial poses of segment 2 for each arm in parallel\n",
    "N, M = len(arm1_interp_toseg2), len(arm2_interp_toseg2)\n",
    "\n",
    "for i in range(max(N, M)):\n",
    "    initialize action with zeros\n",
    "    if i < N:\n",
    "        set action[0:12] to arm1_interp_toseg2[i]\n",
    "    if i < M:\n",
    "        set action[12:24] to arm2_interp_toseg2[i]\n",
    "    env.step(action)\n",
    "\n",
    "# 4. Execute segment2 for each arm in parallel. This segment will be of same length for both arms\n",
    "\n",
    "for i in range(len(arm1_segment2)):\n",
    "    initialize action with zeros\n",
    "    set action[0:12] to arm1_segment2[i]\n",
    "    set action[12:24] to arm2_segment2[i]\n",
    "    env.step(action)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reset environment to new starting poses\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a496069",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate data\n",
    "\n",
    "'''\n",
    "interp_arm1_toseg1 = full_trajectory_outs[\"arm1\"][\"overall_trajectory\"][\"interp_to_segment1\"]\n",
    "interp_arm1_toseg2 = full_trajectory_outs[\"arm1\"][\"overall_trajectory\"][\"interp_to_segment2\"]\n",
    "interp_arm2_toseg1 = full_trajectory_outs[\"arm2\"][\"overall_trajectory\"][\"interp_to_segment1\"]\n",
    "interp_arm2_toseg2 = full_trajectory_outs[\"arm2\"][\"overall_trajectory\"][\"interp_to_segment2\"]\n",
    "seg1_arm1 = full_trajectory_outs[\"arm1\"][\"overall_trajectory\"][\"segment1\"]\n",
    "seg1_arm2 = full_trajectory_outs[\"arm2\"][\"overall_trajectory\"][\"segment1\"]\n",
    "seg2_arm1 = full_trajectory_outs[\"arm1\"][\"overall_trajectory\"][\"segment2\"]\n",
    "seg2_arm2 = full_trajectory_outs[\"arm2\"][\"overall_trajectory\"][\"segment2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0464de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Execute interpolation to initial poses for each arm in parallel\n",
    "'''\n",
    "\n",
    "# obs = obfull[0]\n",
    "# reset_to(env, initial_state) # Reset this to some other state\n",
    "# reset_to_state(env, states_trajectory[0])\n",
    "# obfull = just_reset(env, initial_state) #  --- IGNORE ---\n",
    "\n",
    "obs = obfull[0].copy()\n",
    "\n",
    "N, M = len(interp_arm1_toseg1), len(interp_arm2_toseg1)\n",
    "\n",
    "prev_action = action_trajectory[0]\n",
    "\n",
    "for i in range(max(N, M)):\n",
    "\n",
    "    action = prev_action.copy()\n",
    "\n",
    "    if i == 0:\n",
    "        if i < N:\n",
    "            action[0:12] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg1[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg1[i])[:3, :3]]),\n",
    "                original_action=interp_arm1_toseg1[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=False, #cTrue\n",
    "            )\n",
    "        if i < M:\n",
    "            action[12:24] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg1[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg1[i])[:3, :3]]),\n",
    "                original_action=interp_arm2_toseg1[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=False, #cTrue\n",
    "            )\n",
    "\n",
    "    else:   \n",
    "        if i < N:\n",
    "            action[0:12] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg1[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg1[i])[:3, :3]]),\n",
    "                original_action=interp_arm1_toseg1[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=True\n",
    "            )   \n",
    "        if i < M:\n",
    "            action[12:24] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg1[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg1[i])[:3, :3]]),\n",
    "                original_action=interp_arm2_toseg1[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=True\n",
    "            )\n",
    "\n",
    "    prev_action = action.copy()\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Execute transformed synced trajectory for each arm in parallel - segment 1\n",
    "\n",
    "obs carried forward from previous loop\n",
    "'''\n",
    "\n",
    "# Assert both segments are of same length\n",
    "assert len(seg1_arm1) == len(seg1_arm2)\n",
    "\n",
    "N = len(seg1_arm1)\n",
    "\n",
    "prev_action = action_trajectory[0]\n",
    "\n",
    "for i in range(N):\n",
    "    action = prev_action.copy()\n",
    "\n",
    "    if i == 0:\n",
    "        action[0:12] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg1_arm1[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg1_arm1[i])[:3, :3]]),\n",
    "            original_action=seg1_arm1[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=False, #cTrue\n",
    "        )\n",
    "    \n",
    "        action[12:24] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg1_arm2[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg1_arm2[i])[:3, :3]]),\n",
    "            original_action=seg1_arm2[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=False, #cTrue\n",
    "        )\n",
    "\n",
    "    else:   \n",
    "        action[0:12] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg1_arm1[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg1_arm1[i])[:3, :3]]),\n",
    "            original_action=seg1_arm1[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=True\n",
    "        )   \n",
    "    \n",
    "        action[12:24] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg1_arm2[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg1_arm2[i])[:3, :3]]),\n",
    "            original_action=seg1_arm2[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=True\n",
    "        )\n",
    "\n",
    "    prev_action = action.copy()\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Execute interpolation to initial poses of segment 2 for each arm in parallel\n",
    "'''\n",
    "\n",
    "# obs = obfull[0]\n",
    "# reset_to(env, initial_state) # Reset this to some other state\n",
    "# reset_to_state(env, states_trajectory[0])\n",
    "obfull = just_reset(env, initial_state) #  --- IGNORE ---\n",
    "\n",
    "obs = obfull[0].copy()\n",
    "\n",
    "N, M = len(interp_arm1_toseg2), len(interp_arm2_toseg2)\n",
    "\n",
    "prev_action = action_trajectory[0]\n",
    "\n",
    "for i in range(max(N, M)):\n",
    "\n",
    "    action = prev_action.copy()\n",
    "\n",
    "    if i == 0:\n",
    "        if i < N:\n",
    "            action[0:12] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg2[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg2[i])[:3, :3]]),\n",
    "                original_action=interp_arm1_toseg2[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=False, #cTrue\n",
    "            )\n",
    "        if i < M:\n",
    "            action[12:24] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg2[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg2[i])[:3, :3]]),\n",
    "                original_action=interp_arm2_toseg2[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=False, #cTrue\n",
    "            )\n",
    "\n",
    "    else:   \n",
    "        if i < N:\n",
    "            action[0:12] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg2[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm1_toseg2[i])[:3, :3]]),\n",
    "                original_action=interp_arm1_toseg2[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=True\n",
    "            )   \n",
    "        if i < M:\n",
    "            action[12:24] = eef_to_action_single_arm(\n",
    "                eef_pos=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg2[i])[:3, 3]]),\n",
    "                eef_rot_mats=np.stack([PoseUtils.unmake_pose(interp_arm2_toseg2[i])[:3, :3]]),\n",
    "                original_action=interp_arm2_toseg2[i], # action_trajectory[0],\n",
    "                prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "                prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "                max_dpos=max_dpos,\n",
    "                max_drot=max_drot,\n",
    "                cur_rot_from_env=True\n",
    "            )\n",
    "\n",
    "    prev_action = action.copy()\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df346cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Execute transformed synced trajectory for each arm in parallel - segment 2\n",
    "\n",
    "obs carried forward from previous loop\n",
    "'''\n",
    "\n",
    "# Assert both segments are of same length\n",
    "assert len(seg2_arm1) == len(seg2_arm2)\n",
    "\n",
    "N = len(seg2_arm1)\n",
    "\n",
    "prev_action = action_trajectory[0]\n",
    "\n",
    "for i in range(N):\n",
    "    action = prev_action.copy()\n",
    "\n",
    "    if i == 0:\n",
    "        action[0:12] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg2_arm1[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg2_arm1[i])[:3, :3]]),\n",
    "            original_action=seg2_arm1[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=False, #cTrue\n",
    "        )\n",
    "    \n",
    "        action[12:24] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg2_arm2[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg2_arm2[i])[:3, :3]]),\n",
    "            original_action=seg2_arm2[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=False, #cTrue\n",
    "        )\n",
    "\n",
    "    else:   \n",
    "        action[0:12] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg2_arm1[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg2_arm1[i])[:3, :3]]),\n",
    "            original_action=seg2_arm1[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=True\n",
    "        )   \n",
    "    \n",
    "        action[12:24] = eef_to_action_single_arm(\n",
    "            eef_pos=np.stack([PoseUtils.unmake_pose(seg2_arm2[i])[:3, 3]]),\n",
    "            eef_rot_mats=np.stack([PoseUtils.unmake_pose(seg2_arm2[i])[:3, :3]]),\n",
    "            original_action=seg2_arm2[i], # action_trajectory[0],\n",
    "            prev_eef_pos=np.stack([obs['robot0_eef_pos'], obs['robot1_eef_pos']]),\n",
    "            prev_eef_quat=np.stack([obs['robot0_eef_quat'], obs['robot1_eef_quat']]),\n",
    "            max_dpos=max_dpos,\n",
    "            max_drot=max_drot,\n",
    "            cur_rot_from_env=True\n",
    "        )\n",
    "\n",
    "    prev_action = action.copy()\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexmimicgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
